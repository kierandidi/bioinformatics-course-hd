---
layout: post
title: Lesson 3 - A Zoo of Models
image: /assets/img/lessons/nn_zoo.png
accent_image: 
  background: url('/assets/img/blog/jj-ying.jpg') center/cover
  overlay: false
accent_color: '#ccc'
theme_color: '#ccc'
description: >
  The revolution will not be supervised
invert_sidebar: true
---

# Lesson 3 - A Zoo of Models

### Required reading for this lesson

- [Jay Alammar - The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [far1din - Convolutional Neural Network Playlist](https://www.youtube.com/playlist?list=PL1sQgSTcAaT7MbcLWacjsqoOQvqzMdUWg)

### Optional reading for this lesson
- [D2L Book Chapter on Attention and Transformer](https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html)
- [PyTorch Lightning - Deep Learning Course, Unit 8 explaining Attention and Language Models](https://lightning.ai/courses/deep-learning-fundamentals/unit-8.0-natural-language-processing-and-large-language-models/)

### [Slides](/assets/slides/03_modelzoo.pdf)

#### Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/kf0qCNwOKCI?si=pYEbVBnwVvk0e001" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

### Credits

The title image of this exercise is from an excellent review paper by Mohammed AlQuraishi & Peter K. Sorger called [Differentiable Biology](https://www.nature.com/articles/s41592-021-01283-4); a highly recommended read!

Some of the visualisations in the video were created via the fantastic [ManimML library](https://github.com/helblazer811/ManimML); see [their paper](https://arxiv.org/pdf/2306.17108.pdf) for more details on it! Also thanks to Nicholas Gale and Stephen Eglen for allowing me to use some of their amazing figures in this lecture!

*[SERP]: Search Engine Results Page
